{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b351f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from Bio import SeqIO\n",
    "from Bio import pairwise2\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0b7e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfold_train_data_path = '/data/JSG/mapping_list/240226_deepfold_train_data_list.json'\n",
    "#jsg_train_data_path = '/data/JSG/240226_JSG_protein_mapping.json'\n",
    "\n",
    "fasta_root = '/data/JSG/fasta/'\n",
    "fastas = os.listdir(fasta_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fa93d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(deepfold_train_data_path, \"r\") as f:\n",
    "    cluster_info = json.load(f)\n",
    "    \n",
    "#with open(jsg_train_data_path, \"r\") as f:\n",
    "#    protein_targets = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea6f5eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(features) 16441\n",
      "len(MSAs) 533503\n",
      "len(SAs) 16441\n"
     ]
    }
   ],
   "source": [
    "feature_root = '/data/JSG/240429_feature_dir_with_binned_SA/'\n",
    "feature_candidates = os.listdir(feature_root)\n",
    "\n",
    "features = []\n",
    "for candidate in feature_candidates:\n",
    "    features.append(candidate.split('.')[0])\n",
    "print('len(features)', len(features))\n",
    "\n",
    "MSA_root = '/data1/JSG/alignment_dir/'\n",
    "MSA_candidates = os.listdir(MSA_root)\n",
    "\n",
    "MSAs = []\n",
    "\n",
    "for candidate in MSA_candidates:\n",
    "    MSAs.append(candidate.split('.')[0])\n",
    "print('len(MSAs)',len(MSAs))\n",
    "\n",
    "SAs = []\n",
    "SA_root = '/data/JSG/SolventAcc_binned/'\n",
    "SA_candidates = os.listdir(SA_root)\n",
    "\n",
    "for candidate in SA_candidates:\n",
    "    SAs.append(candidate.split('.')[0])\n",
    "print('len(SAs)',len(SAs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a398dc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20032"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cluster_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92d5cdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = os.listdir('/data/jsg_bk/feature_dir/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa91d911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8d53a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "former_root = '/data/jsg_bk/feature_dir/'\n",
    "after_root  = '/data/JSG/240429_feature_dir_with_binned_SA/'\n",
    "\n",
    "def copy_file(cluster):\n",
    "    try:\n",
    "        name = cluster.split('/')[-1].split('.')[0]\n",
    "        code_name = name.split('_')[0]\n",
    "        chain_name = name.split('_')[2]\n",
    "        protein_name = (code_name + '_' + chain_name).lower()\n",
    "        former_path = os.path.join(former_root, protein_name + '.pkl')\n",
    "        after_path = os.path.join(after_root, protein_name + '.pkl')\n",
    "        \n",
    "        shutil.copy(former_path, after_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to copy for cluster {cluster}: {e}\")\n",
    "\n",
    "# ThreadPoolExecutor를 사용하여 병렬로 파일 복사\n",
    "#with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "#    futures = [executor.submit(copy_file, cluster) for cluster in cluster_info]\n",
    "\n",
    "#    for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "#        pass\n",
    "\n",
    "#print(\"모든 파일 복사가 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53833546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7e8cace03f45a3be65da0f4bf26a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing ./train_data/outputs_384/c7/1c7t_1_A_350.xz: Ran out of input\n",
      "Error processing ./train_data/outputs_384/c7/1c7t_1_A_0.xz: Ran out of input\n",
      "Error processing ./train_data/outputs_384/c7/1c7t_1_A_473.xz: Ran out of input\n",
      "Error processing ./train_data/outputs_384/c2/2c2n_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/k0/4k08_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/h0/1h0h_1_A_592.xz: Ran out of input\n",
      "Error processing ./train_data/outputs_384/h0/4h0p_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/h0/1h0h_1_A_0.xz: Ran out of input\n",
      "Error processing ./train_data/outputs_384/h0/1h0h_1_A_350.xz: Ran out of input\n",
      "Error processing ./train_data/outputs_384/h0/4h0p_1_A_53.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/dz/3dzz_1_A_6.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/dz/3dzz_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/qi/2qic_1_A_0.xz: Ran out of input\n",
      "Error processing ./train_data/outputs_384/tv/4tvv_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/qd/1qdn_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/yb/1yb4_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/x4/2x40_1_A_336.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/x4/2x40_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/vb/1vb5_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/qy/1qyu_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/u7/3u7i_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/e6/6e6s_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/vz/5vzs_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/fo/1fo9_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/nz/1nzj_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/kh/3khy_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/fw/4fw9_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/fw/4fw9_1_A_347.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/xd/2xdn_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/ce/3ce9_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/b7/1b71_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/b2/4b28_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/b2/4b28_1_A_85.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/j0/6j0e_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/g0/5g09_1_A_98.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/g0/5g09_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/j8/2j89_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/xt/5xts_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/xt/5xts_1_A_229.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/g8/6g8w_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/w4/2w4d_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/w4/4w4l_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/hs/4hst_1_B_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/hs/4hst_1_B_158.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/g3/3g3e_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/g3/2g3y_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/pl/2plw_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/py/2pyx_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/py/2pyx_1_A_141.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/ei/5eio_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/hv/3hva_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/g6/1g60_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/d6/2d6y_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/mo/4mow_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/el/5elk_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/bg/1bg8_1_A_0.xz: Ran out of input\n",
      "Error processing ./train_data/outputs_384/d4/2d4l_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/bb/3bbd_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/eo/1eo2_1_B_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/zi/4zi5_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/rx/4rxx_1_A_45.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/rx/4rxx_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/ju/3ju7_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/a7/2a75_1_A_267.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/a7/2a75_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/on/4on1_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/jx/5jx4_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/od/2od5_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/ld/4ldy_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/gs/2gs5_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/f3/2f3n_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/n9/3n9b_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/v7/2v76_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/f6/2f6l_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/ij/6ijn_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/ag/4ag7_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/ag/5ag3_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/dt/3dtn_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/p0/2p0o_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/qx/1qxo_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/qx/1qxo_1_A_3.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/nf/5nfd_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/x6/2x6u_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/qs/2qsw_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/fc/1fc5_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/fc/1fc5_1_A_26.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/ix/4ixn_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/e8/3e8j_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/vo/2vov_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/e3/5e37_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/kg/4kg3_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/nt/4ntc_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/kb/3kbq_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/b6/1b62_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/xk/1xks_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/xk/1xks_1_A_65.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/sz/5szd_1_A_0.xz: pickle data was truncated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing ./train_data/outputs_384/cy/2cy4_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/su/1sur_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/hr/6hr7_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/hr/6hr7_1_A_42.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/g2/6g26_1_E_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/px/3pxv_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/uq/5uqp_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/ec/6ecd_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/ec/5ecc_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/mv/3mvu_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/ef/2ef8_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/jd/5jd0_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/mq/4mqe_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/mq/4mqe_1_A_35.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/uo/3uor_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/uo/3uor_1_A_73.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/ml/4mlz_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/jl/6jls_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/bq/3bqx_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/zk/3zk4_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/zk/4zkh_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/zk/3zk4_1_A_186.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/wf/4wft_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/ru/4ru4_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/ru/4ru4_1_A_217.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/i7/3i7m_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/wa/1war_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/wi/5wir_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/gu/5guf_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/wq/2wqd_1_A_187.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/wq/2wqd_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/dc/3dc7_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/dc/5dck_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/gp/1gp1_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/gp/4gpv_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/gp/6gpa_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/c5/3c5r_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/gx/4gxq_1_A_121.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/gx/4gxq_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/dx/3dx5_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/ds/3ds8_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/qb/3qbt_1_B_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/to/5too_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/to/5too_1_A_164.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/dn/5dn5_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/qj/2qjv_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/fb/2fbh_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/u0/5u0i_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/vk/1vkn_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/qz/6qzo_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/al/3al9_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/al/3al9_1_A_154.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/fj/1fjj_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/x8/4x8q_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/fe/2fe3_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/nc/1nc7_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/fm/3fmb_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/nk/4nkp_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/vv/3vvm_1_A_9.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/vv/3vvm_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/fu/6fuv_1_A_42.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/fu/6fuv_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/xb/5xb7_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/xb/5xb7_1_A_327.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/e5/2e5w_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/sq/1sql_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/cc/3cc9_1_A_11.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/cc/3cc9_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/r1/1r1m_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/kn/3knv_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/b0/4b0z_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/z7/5z7q_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/cf/3cfz_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/j6/4j6j_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/r4/2r44_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/cs/3csq_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/po/2poe_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/xm/2xmo_1_A_58.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/xm/2xmo_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/ky/1ky6_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/hg/4hgn_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/pe/3pe9_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/w5/1w55_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/ht/5htn_1_A_51.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/ht/5htn_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/ej/3ejk_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/us/3usz_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/us/3usz_1_A_437.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/us/3usz_1_A_350.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/d7/3d7c_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/jc/4jcc_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/y1/5y1a_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/d2/3d2o_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/l0/4l0p_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/mx/3mx8_1_A_0.xz: pickle data was truncated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing ./train_data/outputs_384/bh/3bhn_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/zb/2zb2_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/zb/2zb2_1_A_350.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/zb/2zb2_1_A_464.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/d5/2d5l_1_A_321.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/d5/4d5g_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/d5/4d5g_1_A_204.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/d5/2d5l_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/zo/4zos_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/a5/6a5f_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/bp/5bp2_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/jn/4jnw_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/rl/1rli_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/zj/4zj1_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/ry/4ryk_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/bx/5bx9_1_A_31.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/bx/5bx9_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/a8/3a8r_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/wr/1wru_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/ob/4obb_1_A_10.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/ob/4obb_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/f1/2f1f_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/v5/1v5h_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/or/1oru_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/n2/3n28_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/n2/4n2o_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/go/2go7_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/gw/3gwz_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/gw/3gwl_1_A_0.xz: pickle data was truncated\n",
      "Error processing ./train_data/outputs_384/yd/1yd9_1_A_0.xz: pickle data was truncated\n"
     ]
    }
   ],
   "source": [
    "#\"\"\"\n",
    "protein_candidate = []\n",
    "\n",
    "i = 0\n",
    "for cluster in tqdm(cluster_info):\n",
    "    name = cluster.split('/')[-1].split('.')[0]\n",
    "    code_name = name.split('_')[0]\n",
    "    chain_name = name.split('_')[2]\n",
    "    protein_name = (code_name + '_' + chain_name).lower()\n",
    "\n",
    "    if (protein_name in features) and (protein_name in SAs) and (protein_name not in protein_candidate):\n",
    "        try : \n",
    "            feature_path = os.path.join(feature_root, protein_name) + '.pkl'\n",
    "            with open(feature_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "\n",
    "            #if data['aatype'].shape[0] > 0 :\n",
    "            if data['solvent_acc_mask'].sum() > 0  and data['aatype'].shape[0] > 0 :\n",
    "                protein_candidate.append(protein_name)\n",
    "                i += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {cluster}: {str(e)}\")\n",
    "            \n",
    "    if i == 2000:\n",
    "        mapping = {}\n",
    "        for i, candidate in enumerate(protein_candidate):\n",
    "            mapping[i] = candidate\n",
    "        with open('/data/JSG/mapping_list/240621_JSG_protein_mapping_new_2000.json', 'w') as json_file:\n",
    "            json.dump(mapping, json_file, indent=4)\n",
    "            \n",
    "    if i == 5000:\n",
    "        mapping = {}\n",
    "        for i, candidate in enumerate(protein_candidate):\n",
    "            mapping[i] = candidate\n",
    "        with open('/data/JSG/mapping_list/240621_JSG_protein_mapping_new_5000.json', 'w') as json_file:\n",
    "            json.dump(mapping, json_file, indent=4)    \n",
    "                \n",
    "    if i == 10000:\n",
    "        mapping = {}\n",
    "        for i, candidate in enumerate(protein_candidate):\n",
    "            mapping[i] = candidate\n",
    "        with open('/data/JSG/mapping_list/240621_JSG_protein_mapping_new_10000.json', 'w') as json_file:\n",
    "            json.dump(mapping, json_file, indent=4)    \n",
    "            \n",
    "mapping = {}\n",
    "for i, candidate in enumerate(protein_candidate):\n",
    "    mapping[i] = candidate\n",
    "with open('/data/JSG/mapping_list/240621_JSG_protein_mapping_new_full.json', 'w') as json_file:\n",
    "    json.dump(mapping, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acb1f37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16260"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8203b1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/JSG/240429_feature_dir_with_binned_SA/3lcz_a.pkl'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3acf3d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16260"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(protein_candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d86bc5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16441\n"
     ]
    }
   ],
   "source": [
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86a69020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['aatype', 'between_segment_residues', 'domain_name', 'residue_index', 'seq_length', 'sequence', 'all_atom_positions', 'all_atom_mask', 'resolution', 'release_date', 'is_distillation', 'template_aatype', 'template_all_atom_positions', 'template_sum_probs', 'template_all_atom_mask', 'deletion_matrix_int', 'msa', 'num_alignments', 'solvent_acc', 'solvent_acc_binned', 'solvent_acc_real', 'solvent_acc_mask'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(feature_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0569df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53, 10), (53,), (53,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['solvent_acc_binned'].shape, data['solvent_acc_real'].shape, data['solvent_acc_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99377065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4a1cc2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 9, 4, 2, 5, 8, 5, 2, 3, 4, 5, 0, 6, 5, 1, 7, 5, 6, 0, 4, 5, 7,\n",
       "       7, 6, 4, 0, 4, 6, 0, 7, 4, 7, 0, 2, 3, 4, 1, 6, 4, 0, 2, 5, 3, 4,\n",
       "       6, 5, 5, 6, 8, 2, 5, 9, 9])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['solvent_acc_binned'].argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc09978b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['solvent_acc_binned'].sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63edccef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([192.01288635, 142.50012949,  72.45769296,  30.1907054 ,\n",
       "        83.32634691, 131.63147555,  76.08057761,  45.88987221,\n",
       "        71.25006475,  62.79666723,  78.49583404,   0.        ,\n",
       "        97.8178855 ,  95.40262907,  18.11442324, 125.59333447,\n",
       "        39.85173113,  73.66532118,   0.        , 100.23314193,\n",
       "        96.61025728, 136.46198841, 103.85602658, 115.93230874,\n",
       "        61.58903902,   1.20762822,  70.04243653, 121.97044982,\n",
       "         7.2457693 , 130.42384733,  32.60596183, 147.33064236,\n",
       "         2.41525643,  32.60596183,  53.13564151,  82.11871869,\n",
       "        25.36019254,  78.49583404,  80.91109047,   7.2457693 ,\n",
       "        31.39833362,  82.11871869,  62.79666723,  83.32634691,\n",
       "       120.7628216 , 123.17807804,  91.77974442, 137.66961663,\n",
       "       163.02980917,  56.75852615, 100.23314193, 181.14423241,\n",
       "       192.01288635])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['solvent_acc_real']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06def413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['solvent_acc_binned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30c9f34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JSG_crosslink",
   "language": "python",
   "name": "jsg_crosslink"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
